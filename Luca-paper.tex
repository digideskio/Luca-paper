%%%%%%%%%%%%%%%%%%%% author.tex %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% sample root file for your "contribution" to a contributed volume
%
% Use this file as a template for your own input.
%
%%%%%%%%%%%%%%%%%%%% author.tex %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\RequirePackage{fix-cm}

% RECOMMENDED %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[smallextended]{svjour3} 

% Choose options for [] as required from the list in the Reference Guide

\usepackage{mathptmx} 	% selects Times Roman as basic font
\usepackage{helvet} 		% selects Helvetica as sans-serif font
\usepackage{courier} 		% selects Courier as typewriter font
\usepackage{type1cm} 		% activate if the above 3 fonts are
								% not available on your system

\usepackage{makeidx} 		% allows index generation
\usepackage{graphicx} 	% standard LaTeX graphics tool

% when including figure files
\usepackage{multicol} 						% used for the two-column index
\usepackage[bottom]{footmisc} 			% places footnotes at page bottom
\usepackage{amsmath,amssymb,epsfig}
\usepackage{epstopdf}
\usepackage{multirow}
\usepackage{colortbl}
\usepackage{longtable} 
\bibliographystyle{spmpsci}

% See the list of further useful packages in the Reference Guide
\smartqed  % flush right qed marks, e.g. at end of proof

%\makeindex 	% used for the subject index
				% please use the style svind.ist with
				% your makeindex program

% RECOMMENDED %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Use the package "url.sty" to avoid problems with special characters used in your e-mail or web address
\begin{document}
%\title{Gaze-based control of robot-swarm using electroencephalography} % Fix!
%\title{EEG-based proximal interaction between humans and groups of robots}
%\title{EEG-based implicit communication between human and robots}
\title{Electroencephalography as implicit communication channel for proximal interaction between human and robot swarm}
%\title{Proximal interaction between an operator and a group of robots based on electroencephalography} % Fix!

\titlerunning{EEG as implicit communication channel for proximal interaction between human and swarm}% for an abbreviated version of your contribution title if the original one is too long

\author{Luca Mondada \and
	Mohammad Ehsanul Karim  \and
	 Francesco Mondada}
%\authorrunning{L Mondada, M E Karim and F Mondada}

% Use \authorrunning{Short Title} for an abbreviated version of your contribution title if the original one is too long

\institute{Luca Mondada \at
	Department of Physics, Swiss Federal Institute of Technology ETHZ, Z\"urich, Switzerland \\
	\email{lmondada@ethz.ch}
	\and
	Mohammad Ehsanul Karim \at
	Laboratoire de Syst\`emes Robotiques, Ecole Polytechnique F\'ed\'erale de Lausanne, Lausanne, Switzerland \\
	\email{ehsan.mce@gmail.com}
	\and
	Francesco Mondada \at
	Laboratoire de Syst\`emes Robotiques, Ecole Polytechnique F\'ed\'erale de Lausanne, Lausanne, Switzerland \\
	\email{francesco.mondada@epfl.ch}
	} % Fix!

\date{Received: date / Accepted: date}

\maketitle

% @lucacomment "such techniques are not very intuitive". I'm not sure we can say that as some of those techniques do aim at being as intuitive as possible...
\begin{abstract}

Search and rescue, autonomous construction, and many other multi-robot semi-autonomous robotics applications can benefit from an efficient interaction between an operator and a group of robots. 
%Among the possible control schemes, some take advantage of a shared environment between human and robot and are based on proximal interactions. 
When interacting with a swarm of robots, it is interesting for the operator to follow the rules of swarm interaction, sharing the physical environment of the robots and using local proximal interaction.
Most research on proximal interaction with groups of robots has studied gesture and speech recognition to select the robots among the group or to give orders. 
Such explicit communication techniques require specific conventions in gestures or speech that need to be learned and can be culture-dependent. 

This study proposes a new, implicit, and proximal communication technique to approach the problem of robot selection. We use electroencephalography (EEG) signals to select the robot the operator is looking at. This is achieved using the steady-state visually evoked potential (SSVEP), a repeatable neural response to a regularly blinking visual stimulus that varies predictively based on the blinking frequency. In our experiments, the robot was equipped with LEDs blinking at different frequencies, and the operator's SSVEP signal was analyzed to detect and select the robot. This study systematically investigates several factors that directly impact the efficiency of the system in the specific case of a human - multiple robot interaction. In particular, we study two algorithms and the various associated tuning parameters: distance between the robot and the operator, the LED color, and the LED blinking frequency. Finally, based on these studies, we propose a methodology and critically analyze its performance on 10 subjects controlling a set of physical robots. 
Our results show that despite the numerous artifacts, it is possible to achieve a recognition rate higher than 86\% on some subjects, the average on ten subject being at 75\%.

\keywords{human-robots interaction \and EEG \and SSVEP \and Emotiv EPOC \and Thymio robot}
\end{abstract}

\section{Introduction}
\label{sec:introduction}
Swarm robotics has extremely promising applications, such as search and rescue, environmental monitoring, autonomous construction, or geographic mapping. 
The topic has been extensively studied under various perspectives: swarm robotics \cite{brambilla2013}, collective robotics \cite{kernbach2013handbook}, or distributed robotics \cite{martinoli2012distributed}, depending on the form of interaction among the robots. 
To date, researchers and engineers have successfully designed scalable \cite{rubenstein2012kilobot}, robust \cite{winfield2006safety}, efficient (compared to single robot) \cite{Bonani2012}, and affordable distributed multi-robot systems \cite{rubenstein2014programmable}. 
On top of the challenge in designing autonomous control strategies, researchers have recently shown an increasing interest for another aspect of swarm robotics: human-robot interaction. 
Although many single-robot control interfaces have shown interesting results, human-swarm interaction (HSI) is still a state-of-the-art problem~\cite{Kolling2016}. \\
%In this paper we will use the acronym HRsI (\textit{robot} pluralized) to define human-robot interaction with groups of robots, these being swarms or simply multiple individual robots.\\
\\
A majority of researchers addressing the interaction with a group of robots use remote control strategies, based on a centralized approach allowing the operator to have an overview of the mission. 
This approach contrasts with several basic principles of swarm-robotics, relying on simple mechanisms, local interactions and spatially targeted communication, among others. 
These principles, normally applied to robots only, can also be considered for human-robot interaction.
This is possible, for instance, when human and robot swarm share the same physical environment. 
In these situations, the operator can have a local interaction with the part of the swarm close to him/her, and can observe the same environment that the robots observe. 
In the literature, this interaction is called \textit{proximal}, in opposition to \textit{remote} interactions~\cite{Kolling2016}.\\
\\
%Triggering the interaction with a specific robot can either allow the operator to control a robot working independently within a group or to control a swarm, for instance through a leader~\cite{Goodrich2012}.
We therefore consider a scenario where an operator is surrounded with mobile robots that have semi-autonomous behavior. The robots can be either acting independently or be part of a swarm. 
The operator simply interacts with the robots that are close to her/him and share the same environment.
In our scenario, when the robots meet a predefined condition, find some interesting information, or cannot solve an issue, they stop and request an action from the operator. We could also imagine an alternative scenario where the robots stopping and asking for interaction with the operators are leaders of sub-groups of a swarm~\cite{Goodrich2012}. As several robots can be in this situation, the operator has to select one of them, based on criteria that are application dependent and managed by the operator himself. Triggering the interaction of a single robot within a group is a challenging HSI problem: we need to use a communication channel easily accessible to the operator, combined with an infrastructure that is distributed and compatible with the swarm-robotics approach.
Fong et al. have proposed a simple selection protocol that uniquely identifies each robot using a numbering system; the selection and manipulation of the robots were performed via remote control \cite{fong2003}. 
Such systems require several explicit coding rules that add on top of the communication channel, reducing efficiency and being incompatible with a distributed system. 
Various other more intuitive methods, such as gesture recognition \cite{Couture-Beil2010,Jones2010,Monajjemi2013,Nagietal2014}, robot-vision-based user-gaze interpretation \cite{Couture-Beil2010,Monajjemi2013,Pourmehr2013}, and speech recognition \cite{Pourmehr2013} have been tested. 
There are several relevant literature reviews on the topic \cite{goodrich2007human,Kolling2016,yanco2004classifying}.\\
\\
Most of the aforementioned methodologies have been tested on real robots. 
For example, automated vision-based detection of hands and face combined with machine learning-based spatial gesture analysis showed successful selection of a single drone from a group of four just by robot vision. 
The research team claimed that their algorithm can scale up to 20 drones \cite{Nagietal2014}. Similar research discussed the capacity of vision-based systems considering varying distance between the operator and the robot; in particular, the studied range was 1 to 4\,m~\cite{Couture-Beil2010}. 
However, speech and gesture interaction systems have some practical limitations: (1) they require prior training of the operator to specific coded words or gestures that can be culture-dependent~\cite{Trovato2013}, limiting intuitive interaction~\cite{Kirchner2015};
(2) they are sensible to the detection of the intention to interact, as they use communication channels that are common with other tasks~\cite{Rzepecki2012}; (3) they are based exclusively on explicit communication, generating heavy protocols~\cite{Kirchner2015}.\\
\\ 
To address these issues, we studied the use of electroencephalography (EEG) signals to address the robot selection problem. 
This approach does not require the definition and learning of explicit communication codes, as it is based on the implicit information extracted by EEG of the operator observing the robot. 
We define \textit{implicit} information as provided by the operator in a passive way, in opposition to \textit{explicit} information exchanged actively~\cite{Kirchner2015}.
We define \textit{implicit} communication as an exchange of \textit{implicit} information.
EEG-based implicit communication is not culture-dependent, and EEG techniques are more reliable than gesture and speech-based techniques in detecting the intention to interact~\cite{Rzepecki2012}.
Recent advances in neuroscience provide us with reliable and affordable devices that allow acquisition of two reliable and well-documented EEG neural responses -- the P300 and the Steady-State Visually Evoked Potential (SSVEP) \cite{Beverina2003,Bi2013,Zhu2010}. 
The P300 neural response is elicited as a reaction to salient stimuli. 
The SSVEP, on the other hand, is measured when a visual stimulus is repeatedly shown at a certain frequency. Although the P300 response has been given more attention, recent studies show that target selection can be achieved efficiently using SSVEP since it is possible to distinguish reliably multiple SSVEP responses corresponding to different frequencies through computational analysis \cite{SSVEPfiability}.
Therefore, we used SSVEP and lights blinking at different frequencies in our robot selection scenario to detect the target being watched by the operator. This suggestion of a new communication channel is compatible with the swarm robotic paradigm but does not solve the question of the distributed infrastructure, that will not be addressed in this paper. For this layer of HSI we refer the reader to the last results in protocols implementing spatially targeted communication~\cite{mathews2015spatially}.\\ 
\\ 
The SSVEP response can be extracted from an EEG signal following several approaches~\cite{Bi2013}. 
Most studies use machine learning based on linear discriminant analysis (LDA), but this approach requires a training phase that we want to avoid, to validate the fact that we use pure implicit communication.
Therefore we decided to apply two other techiniques: a signal processing approach using canonical correlation analysis (CCA), and a simpler short-time Fourier transform (STFT).
The CCA-based approach has been chosen because it does not require training and showed very interesting results on the same equipment we used in our study~\cite{Lin2014}.
The simple short-time Fourier transform (STFT)~\cite{Durak2003} has been chosen because of its relative simplicity and fast response. The delay of the response of the system is probably the major limitation of most SSVEP-based approaches.\\
To obtain the best possible results, we started our study by exploring the role of three key parameters of the system: the distance between the operator and the robot, the color of the visual stimuli, and the frequency of the blinking light. 
Once set the optimal parameters, we tested our approach on ten subjects, most of them without experience in using EEG-based interfaces. \\
\\
This paper is structured as follows. Section \ref{sec:soa} presents a state of the art in SSVEP-based brain-computer interfaces (BCI). Section \ref{sec:methods} gives further details about the experimental setup and, in particular, about the EEG device, the robot, and the general data-collection protocol. 
Section \ref{sec:prestudy} present the study on the three key parameters of our set-up: the color, the frequency, and the distance of the targets. Section \ref{sec:CCA_approach} build on the chosen parameter to study the performances on ten subjects of the CCA and STFT approaches. A discussion section concludes the paper.

\section{State of the art}
\label{sec:soa}
After the pioneering example of BCI for the control of a wheelchair by Millan et al.~\cite{millan2004noninvasive}, the research community has shown a growing interest for this mobile robot interaction technique~\cite{Bi2013}. The main motivation behind these studies is to enable severely disabled people to control wheelchairs. With a better understanding of these techniques, other usages have appeared, including the control of mobile robots by healthy subjects in various applications. The work by Kishore et al.~\cite{kishore2014comparison}, targeting the control of a humanoid robot, is a representative example of the most common approach: the interaction is made through a screen, where all possible commands are associated with visual stimuli~\cite{Volosyak2009}. When the subject look toward a given command, this is triggered by the detection of a response in the EEG signal. Stawicki et al.~\cite{Stawicki2016} also present the possible actions on a screen, but using a subjective perspective based on the video streaming from a camera located on the mobile robot itself. A slightly more sophisticated approach consist in introducing an avatar to represent the possible actions~\cite{Faller2010}. An additional abstraction can be introduced by having the selection of a destination, for instance in the scenario of driving a car~\cite{Fan2015}. Most studies, in this research field, use a computer screen as support for the visual stimulus, like the example given above. Computer screen offer a lot of flexibility in the graphical expression of the commands and in the placement of the simuli. \\
\\
G{\"{u}}neysu et al.~\cite{Guneysu2013} control a humanoid robot with a panel of LEDs instead of a computer screen. Despite the principle is the same as the studies described above, with a set of possible commands displayed on a surface, the choice of LEDs allows a better flexibility in the choice of frequencies. Also Ortner et al.~\cite{Ortner2010} use LEDs on a control panel to define the direction of a mobile robot, but have a specially designed shape for their panel. Still, none of these studies allows a direct proximal interaction with the robot, always introducing a computer screen or a control panel between user and robot. To our knowledge, only Jacobs~\cite{Jacobs2013} studied a direct interaction, with the visual stimuli created by LEDs on the robot itself. In his study, the LEDs are placed at the end of three arms fixed on the robot. The three arms correspond to three directions (forward, right, and left) that the user can choose by looking at the corresponding LEDs. This work was very preliminary and tested on very few subjects.\\
\\
Concerning the choice of the neural response to be used to detect the intention of the user, SSVEP is often chosen as it is usable by most people~\cite{Guger2012}. SSVEP-based target selection procedures allow to choose among many items. Gao et al.~\cite{SSVEPfiability} claimed that their algorithm could successfully detect 45 different target frequencies using green blinking LED lights. Another approach to improve performances of SSVEP-based systems is to couple them with other neural response, like the P300~\cite{yin2015hybrid}. In the domain of rehabilitation, the combination of SSVEP and P300 signals has been used to control actual wheelchairs~\cite{paper4}. These performances come at a cost: they require EEG acquisition systems that are extremely expensive and not portable, and experiments in conditions that are extremely controlled.\\
\\
The goal of reaching practical applications pushed the development of affordable and portable EEG headsets, but most consumer headset have less than 5 electrodes and do not allow to explore a sufficiently large number of signals. Only two affordable systems have between 14 and 16 electrodes: the OpenEEG and the Emotiv EPOC headsets. The OpenEEG is an affordable system targeting research experiments~\cite{Salehuddin2011}, but requires an important deployment effort. The Emotiv EPOC is simpler to deploy~\cite{jian2014improving,van2012designing}. Compared to traditional systems that require gel on the scalp as well as cumbersome wiring, Emotiv uses saline water and a radio connection. However, ease of use and affordability come at the price of poorer signal quality. Still, a comparative analysis of SSVEP data acquired from EPOC and medical-grade EEG found that the data is reliable \cite{liu2012implementation}, although researchers advised not to use Emotiv for medically serious cases \cite{duvinage2013performance}. The radio connection is also a limitation but studies have shown its reliable use in real-time applications~\cite{hvaring2014comparison}.\\
\\
Our goal is to explore the use of neural responses for proximal interaction with a swarm of robots, without a computer screen or a panel of LEDs between robots and operator. The choice of the SSVEP as neural response seems obvious, as well as the choice of he Emotiv EPOC headset. Because of the novel configuration of use, based on the generation of stimuli directly on the robot body, the choice of several parameters seems not trivial. \\
The frequency is the first critical parameter. The blinking frequencies used in the literature are in a range from 4.5\,Hz to 50\,Hz~\cite{Zhu2010}. However, since the signal to noise ratio in EEG is highest in the lower part of the spectrum, some researchers have suggested using low frequencies for SSVEP-based applications \cite{paper6}.\\
The distance between the target and the operator is another critical parameter, but no studies have been carried out, to the best of our knowledge, on the impact of the distance on the SSVEP detection performances.\\
The color is another key parameter. In the literature, white was predominantly preferred over red, green, or blue \cite{paper6,aljshamee2014beyond,aljshamee2016discriminate,cao2012flashing,paper2}. Cao et al. justified the preference: white is a combination of all the primary colors and therefore excites cone-cells associated with red, green, and blue simultaneously \cite{cao2012flashing}. 
Some studies, however, have successfully used red \cite{Faller2010,jian2014improving,paper4} and green \cite{chua2004effects,duvinage2013performance,SSVEPfiability,hvaring2014comparison,paper4,mouli2013performance} stimuli as well. Some studies observed even red to be more effective than white \cite{Faller2010,hvaring2014comparison}, while others found green to be more effective under similar comparative conditions \cite{chua2004effects,duvinage2013performance}. 
There is also contradictory evidence between the red and green colors; Mouli et al. observed green to be more effective \cite{mouli2013performance}, while others were more successful using red~\cite{cao2012flashing}. Therefore we decided to conduct our own study on the impact of color of stimuli on our SSVEP response detection.


%Considering Emotiv EPOC, red stimuli was empirically observed to be more effective than white \cite{hvaring2014comparison}.
%Finally, the time needed by the operators in most target selection setups is, in general, at least 3\,s~\cite{Fan2015,SSVEPfiability,jian2014improving,paper4}.
%In some cases (here in real driving conditions), the target selection process can take up to 26\,s~\cite{Fan2015}.

\section{Material and methods}
\label{sec:methods}
For the acquisition of EEG signals, we used the EMOTIV EPOC EEG headset \cite{stytsenko2011evaluation}. 
As described in Section \ref{sec:soa} above on the state of the art, this headset is a good tradeoff between affordable price and level of performance. 
It is affordable with respect to medical-grade devices; however it is expensive (approximately \$700 with drivers to access raw data) compared to other ``consumer'' headsets because of its 14 electrodes (see Figure \ref{fig:electrodes} for their positioning on the skull), allowing several types of data acquisition. 
This and other aforementioned features are sufficient to allow for interesting experiments and make it a good candidate for concrete use in robotic applications. A final advantage is its compatibility with open-source EEG signal acquisition and processing software for BCI design. This study uses OpenViBE, a well-established open-source BCI design software \cite{ov_publication}.\\
\\
\begin{figure}
\center
\includegraphics[width=0.5\textwidth]{figures/emotiv-electrodes.pdf}
\caption{Top view of the location of the electrodes of the EMOTIV EPOC EEG headset on the skull (forward looking direction toward the top of the image), with their international code labeling.} \label{fig:electrodes}
\end{figure}
\\
As the robot for our experiments, we used Thymio II; this programmable robot features a differential drive system, infrared (IR) remote control receiver, and LEDs to change body color \cite{Riedo-et-al-2013}. Its small size ($11 \times 11 \times 5\,\mathit{cm}$) and affordable price (approximately \$130) make it well suited for multi-robot experiments. 
The communication between the computer and the robot was supported by an infrared emitter dongle controlled by USB. 
In this configuration, the computer only plays the role of the processing and communication unit of the operator, establishing local communication with the robots that are in the field of view of the operator.\\
\\
Given our HSI problem of selecting a particular robot from a group of robots, the initial task was to design or select an algorithm. 
In our study, we decided to test three well-known algorithms from the literature: linear discriminant analysis (LDA) \cite{openvibeSSVEP}, Lin's canonical correlation analysis (CCA) separator \cite{Lin2014},
and a short-time Fourier transform. The first approach was chosen because it is the most common processing method applied in human-robot interaction based on SSVEP (see Table IV in \cite{Bi2013}), despite the required training phase.
In a second setup, the CCA was chosen because of its good performances classifying SSVEP signals obtained with the same headset we used. The optimization of parameters was performed only on this second, more promising algorithm.
Lastly, on the same data sets as the CCA, we computed offline the recognition rates of a standard STFT signal processing for reference purposes.
In both experiment setups, all training and test sessions were performed in a setup which included an operator and a set of real robots.\\

\section{Preliminary study: parameter optimization}
\label{sec:prestudy}
%This section provides details about the experimental setup and the data-collection protocol used for collecting data to test on the LDA-based algorithm \cite{openvibeSSVEP}.\\

To optimize the extraction of the SSVEP within the EEG signal, we studied the impact on the strength of the SSVEP response of three important interaction parameters: blinking frequency, blinking color, and distance to the stimulus. 
These studies not only make sense within the context of HSI but also have more fundamental scientific interest. 
To our knowledge, there has not been any study featuring the range of these stimulus parameters in the framework of human-robot interactions. We only know from generic EEG literature that the recognition reliability decreases if either frequency or the distance to stimulus target increases \cite{herrmann2001,wu2013effect}. 
Concerning the color of the stimuli, we know that the color white can emit three times as much light as red, green, or blue and stimulates all three cone cells in the eye, which could potentially lead to stronger neural responses \cite{aljshamee2016discriminate,cao2012flashing}. 
However, existing literature states that ``it is difficult to decide which color is the best'' for SSVEP~\cite{Zhu2010}.
Finally, the impact of these parameters for the acquisition of data by our specific headset is unknown. 
Given the reduced signal acquisitive capability of the Emotiv EPOC device as compared to standard medical-grade EEG headsets, we expect the limits to be significantly lower.\\

\begin{figure} \center
\includegraphics[width=\textwidth]{figures/schema-global.pdf}
\caption{Configuration of the experiment: the left side illustrates the spatial arrangement of the experiment; the right summarizes the signal acquisition and the processing method.} \label{fig:thymioinstall}
\end{figure}

\subsection{Experimental setup and data collection}
Figure \ref{fig:thymioinstall} summarizes the experimental setup. 
The subjects were placed in front of three robots. 
Each experiment was composed by a set of trials. In each trial, the subjects were instructed to look at an indicated target robot. 
One second after the instruction, all three targets began to flicker for 7\,s. During the stimulus, the subjects were asked to look at the blinking light; moreover, they were requested to blink as little as possible to limit EEG artifacts. 
A break of 3\,s was then introduced to avoid tiring the subject. 
This process was repeated eight times for each target frequency plus a neutral non-blinking condition. \\
%Finally, to reward the subjects, we implemented a visualization where the successful recognition is displayed on the robot's LEDs by turning them green as soon as the classification has been made, and then making the chosen robot controllable by a remote control.\\
\iffalse
--------

; the subjects had normal or corrected-to-normal vision and no history of major head injury. 
Both had previous experience with EEG and were excellent candidates for experiments. 
This hypothesis was confirmed in the second study presented in this paper, where one of the two subjects, referred as \textit{Subject1}, achieved the best recognition scores. \\
\\

--------
\fi
The frequency spectrum corresponding to each parameter was calculated using fast Fourier transform. 
To quantify the detectability of the SSVEP, we used the \textit{first peak to the second peak ratio} (FSR)~\cite{Zheng2010}:
given a particular frequency $f$, let $F$ and $R$ be two disjoint subsets of the averaged spectrum such that $F$ contains the spectrum of the frequencies $[f-1, f+1]$, and $R$ contains the frequency range $[6, f-1[ \,\cup\, ]f+1, 24]$; the FSR ratio is then defined as:
\begin{equation}
\label{recog_rat}
q =:\frac{\max F}{\max R}
\end{equation}
\\
The FSR provides the ratio of the highest peak within $[f-1, f+1]$ to the highest peak in the rest of the spectrum. 
The neural response to a regularly blinking stimulation, called SSVEP, is characterized by a peak in the spectrum of the signal at the same frequency as the blinking frequency. 
Thus, if the FSR based on the stimuli frequency is above 1, then the highest peak is within 1\,Hz of $f$, and the SSVEP can be considered detectable and recognized. 
Otherwise, the SSVEP cannot be observed. 
We therefore call $q$ the \textit{recognition ratio}.
Please note that we decided to consider peaks up to 1\,Hz off from the stimulation frequency as valid SSVEP responses because we always have at least 2\,Hz difference between one stimulation frequency and another. 
This band could be restricted, as existing literature shows that neural responses are, in general, very accurate~\cite{SSVEPfiability}.

\subsection{Parameter: Stimulation frequency}
% @lucacomment Here we have a serious problem: the definition of the recognition ratio goes up to 18Hz whereas we apparently make measures up to 24Hz, which does not make much sense...
% I don't know if it was my mistake at the time of plotting (I hope not!) or if it is a writing mistake...
Six frequencies were tested (9, 12, 15, 18, 21, and 24\,Hz). For each frequency condition, five trials were performed on three different subjects. The subjects had normal or corrected-to-normal vision and no history of major head injury. The blinking light was set 1\,m away from the subject. 
Figure \ref{fig:graph-frequences} confirms the decrease in the amplitude of the neural response as the frequency grows as already described in the existing literature~\cite{herrmann2001}; furthermore, it shows that the detection fails beyond 15\,Hz. 
This is lower than what was observed in the literature with medical-grade EEG headsets; in \cite{SSVEPfiability}, the range used is 6 to 24\,Hz. Therefore, we deduced that SSVEP activity can be measured with this headset and in these physical conditions, but provided that low frequencies are chosen.
Based on these observations, we restricted the frequency band in the following two studies; the chosen interval was [7\,Hz, 17\,Hz].

\begin{figure}
\center
\includegraphics[width=0.8\textwidth]{figures/graph-frequences.pdf}
\caption{Recognition of a red visual stimulus in the EEG spectrum based on its blinking frequency. Each of the three subjects has been subjected to five trials for each frequency; the trial period is 7\,$s$. The plotted recognition ratios for each frequency represents the values of the averaged power spectrum of the five stimulation trials.} \label{fig:graph-frequences}
\end{figure}

\subsection{Parameter: Stimuli distance}
As a second parameter, we analyzed the impact of varying distance between the operator and the blinking target robots, taking into consideration each of the frequencies: 7, 9, 12, 15, and 17\,Hz; the tested distances were: 30\,cm, 1\,m, and 2\,m. 
Considering the small size (12\,cm in diameter) and the weak light emitting power of the robot (< 300\,mW electrical power), these experimental distances correspond to a range of 1.5\,m to 10\,m for a robot of a diameter of 60\,cm with a 7.5\,W light, corresponding to a standard LED lamp. 
For proximal interaction of a operator directly in contact with the robot, this range seems compatible with real-world applications.
The experiment was conducted on three subjects, where on each subject we performed four acquisitions for each frequency and each distance. 
Figure \ref{fig:graph-distances} summarizes the results; there is not much difference in neural response between 30\,cm and 1\,m; however, the response starts to deteriorate at 2\,m. Indeed, the recognition ratio at 2\,m falls under 1.0 at 13\,Hz. 
The reasons are: (1) the targets become smaller with increasing distance and (2) the LED light intensity deteriorates, leading to a weaker SSVEP response.

\begin{figure}
\center
\includegraphics[width=0.8\textwidth]{figures/graph-distances.pdf}
\caption{Recognition of a red visual stimulus in the EEG spectrum based on the distance of the robot. Four trials per subject for each distance and frequency combination was performed. The plotted recognition ratio for each frequency and distance combination represent the values of the averaged power spectrum of all the stimulation trials on all the subjects.}
\label{fig:graph-distances}
\end{figure}
%Fixed!
\subsection{Parameter: Stimulation color}
The experiment featuring stimulus color was similar to the stimulus-distance one. Four trials were conducted for each combination of frequency (7, 9, 12, 15, and 17\,Hz) and LED color (red, green, and white). The target robot was at 1\,m from the subjects. Figure \ref{fig:graph-couleurs} shows that the best results were obtained using the red or green stimuli, which conforms to part of the literature \cite{chua2004effects,duvinage2013performance,Faller2010,hvaring2014comparison}. Moreover, white color does not increase the neural response; therefore, our results contradict the findings of Cao et al. as documented in \cite{cao2012flashing}. 

\begin{figure}
\center
\includegraphics[width=0.8\textwidth]{figures/graph-couleurs.pdf}
\caption{Recognition of a visual stimulus in the EEG spectrum based on its color. Four trials per subject for each color and frequency combination were performed. The plotted recognition ratios for each frequency and distance combination represent the values of the averaged power spectrum of all the stimulation trials on all the subjects.} \label{fig:graph-couleurs}
\end{figure}

\section{Second study: Robot selection using CCA-based SSVEP classifier}
\label{sec:CCA_approach}

\subsubsection{Experimental setup and data collection}
Based on the results of the short studies described above, we designed an experiment to implement and test the robot selection methodology using CCA-based SSVEP analysis. The schematics of this setup can be found in Figure \ref{fig:experiment-set-up}.
XXX
This section begins by highlighting the three short studies on parameter tuning (frequency, distance to the stimuli, and LED color). The outcome of these individual studies is then taken into account to design and propose an improved robot selection methodology based on canonical correlation analysis (CCA), which does not require training. 
%The experimental setup and the data-collection protocol for the CCA-based experiment is also presented in this section. 
The CCA can be thought of as a generalization of the correlation measure to multivariate signals. 
This particular algorithm was chosen because Lin et al. achieved good results with the same headset using CCA to address SSVEP classification \cite{Lin2014}. The principle of this approach is as follows: given two multivariate signals $X$, $Y$, the optimization problem of CCA is to find $\rho$ such that
\\
\begin{equation}
\label{rho}
\rho = \max_{a, b \in \mathbb R^n} r_{ a^\top X, b^\top Y}
\end{equation}
Here, $r_{a^\top X, b^\top Y}$ is the correlation between $a^\top X$ and $b^\top Y$. This is achieved when $a$ is the eigenvector associated to the largest eigenvalue of $S(X, X)^{-1} S(X,Y) S(Y, Y)^{-1} S(Y, X)$; and $b$ is a similar eigenvector of $S(Y, Y)^{-1} S(Y, X) S(X, X)^{-1} S(X, Y)$, where $S(X, Y)$ is the covariance matrix. The proof can be found in \cite{rencher2003}.
XXXX


Three Thymios blinking in red at frequencies of 8, 10, and 12\,Hz are placed in a half circle, 90 degrees apart.
The subject is equipped with an IR remote control and has her/his EEG signal analyzed in real-time using the CCA algorithm.
The subject then looks at the robot she/he wants to control, and the EEG signals acquired from the Emotiv device are used to make a prediction with the processing chain.
This information is transmitted via IR to the robots.
The selected robot turns green and executes the command received from the IR remote control while the other robots remain red and ignore these commands.\\
\\
The subject was exposed to 15 trials of 15\,s each: 5 trials at each frequency. Before each trial, the subjects were told which of the three robots she/he should look at and was given 4\,s to prepare. During the trial, the subject had to concentrate on one robot even though all three robots were blinking; a 3\,s break followed each trial.
To assess the reliability of this methodology, the experiment was conducted on 10 different subjects with mostly no previous experience with EEG.
The subjects were aged between 17 and 48: three women (age: 17, 32, and 44) and seven men (age: 18, 18, 19, 29, 35, 37, and 48). 

\begin{figure}
\center
\includegraphics[width=0.9\textwidth]{figures/schema-global2.pdf}
    \caption{Setup of the experiment, showing the configuration of the subject with respect to the robots and the communication channels used for interaction. The detailed schematics of the computational unit (signal acquisition and processing chain) are the same as shown in Figure \ref{fig:thymioinstall}.} \label{fig:experiment-set-up}
\end{figure}

\subsubsection{Processing chain for data analysis}
Figure \ref{fig:schema-openvibe-cca} shows the details of the processing chain.
The objective of the processing chain is to classify the EEG signal from the occipital region of the brain (O1 and O2) using SSVEP into one of the following three categories: 8\,Hz, 10\,Hz, and 12\,Hz.
The processing chain consists of a loop that is repeated until a successful classification can be made.
After each unsuccessful iteration, a signal length parameter is increased. Initially this parameter is set to 2\,s.
It represents the length of the signal that is used during the classification attempt.
In the event of classification failure, a new attempt is made with an increased signal length.
This increased length boosts the chances of success of the new classification attempt by reducing the impact of the noise present in the signal
but at the same time introduces longer recognition delays as changing states do not affect the predictions as quickly as before.
If the signal length parameter reaches 8\,s, the classification is interrupted and no prediction is made.
Each loop iteration ends with a classification attempt.
A classification is considered successful only if four consecutive classification attempts have made the same prediction. This measure significantly reduces the false positives.

During each iteration, the classification attempt is made using CCA: the measured EEG signal is correlated with three other signals that are precomputed, and then the signal frequency with the highest correlation to the measured signal is chosen.
Each of these precomputed signals models an idealized reaction to one of the three different blinking stimulations (blinking frequencies of 8\,Hz, 10\,Hz and 12\,Hz).
For a given stimulation frequency, the model is composed of the sine, cosine and the first harmonic of that frequency.
Indeed, SSVEP signals are characterized by amplitude peaks in the frequency spectrum at the respective blinking stimulation.
Using linear combinations of these multidimensional signals, phase, and amplitude as well as superposition of harmonics known to be present in SSVEP signals~\cite{herrmann2001} can thus be modulated arbitrarily to model the SSVEP response of the brain and maximize the correlation with the measured signal.

\begin{figure}
\center
\includegraphics[width=0.9\textwidth]{figures/schema-openvibe-cca.pdf}
\caption{The signal processing chain uses the occipital signals O1 and O2. These signals are first buffered; only the last part of the buffer is used for processing. The length of this period is variable and increased at each processing loop. The signal is compared with ideal signals and the best fit is selected. Four consecutive coinciding predictions are required to have a final selection. The loop is terminated when such a selection is made or when the whole buffer of 8\,s has been used.}
\label{fig:schema-openvibe-cca}
\end{figure}

\subsubsection{Results and discussion}
Figure \ref{fig:all_time_reconn} shows the recognition rate as a function of time; the data presented was averaged over all predictions made on all 10 subjects in all stimulations.
It can be seen that the recognition rate starts randomly and increases gradually to plateau around 75\%.
The same increase in recognition reliability after 4\,s can also be seen in Figure \ref{fig:taux-reconn}; this graph shows the average recognition rate per frequency.
We can observe that the lowest reliability is at 12\,Hz, while the highest is at 10\,Hz with very little standard deviation.
The variance between the subjects can be observed in more detail in Figure \ref{fig:all-results-reconn}; these graphs show the average recognition rates per subject per frequency.
The predominant reliability of 10\,Hz can be seen in different subjects but especially in Subjects 5 and 7, where the recognition rate at 10\,Hz is double compared to 12\,Hz.
Lastly, this graph also shows the divergences between different people: Subject 1 has a 98\% recognition rate at 8\,Hz, while Subject 5 is around 40\% for the same frequency.
This very high variability is a characteristic of EEG that makes EEG analysis so delicate and must be carefully considered when developing new applications.\\
\\
For comparison, we also computed the STFT on the same data sets.
Starting at the beginning of a stimulation period, the STFT was computed using time frames as long as possible (up to 4\,s) using the available signal, since longer time frames give higher spectrum resolution. %, which is key to limiting the impact of EEG noise.
We therefore used a time frame of 0.5\,s during the first second, of 1\,s in the second second, of 2\,s up to the fourth second, and then a time frame of 4\,s.
However, we can see in Figure \ref{fig:all_time_reconn} that the STFT performed significantly worse than CCA.\\
%Its one potential advantage is the possibility to use only much shorter time frames as CCA,
%possibly leading to shorter recognition delays.
%However, in our current scenario, this effect is trumped by its higher sensitivity to EEG signal noise.\\
\\
%Fixed! (ADD REFERENCE)
Based on the results, we can observe that the time required to recognize and select the robot in a reliable way is four seconds. 
Due to the CCA approach and the loop structure of this particular processing chain, the first prediction using exclusively EEG signals acquired during the current stimulation can only be made three seconds after the beginning of the stimulation.
An additional second is required to reach the best performances, which matches results achieved in the literature \cite{Fan2015,SSVEPfiability,jian2014improving,paper4}. 
Although this signal processing chain does not require a training session, as opposed to systems that use machine learning algorithms, this delay of 4\,s is a clear drawback of this prediction system. 
With further study, this issue could perhaps be addressed using a hybrid processing chain combining the reliability of CCA with the reactivity of STFT.
Nonetheless, the stability of this setup is remarkable: it shows that despite the numerous artifacts, it is possible to guarantee, on average, a recognition rate of 75\% at any time after the first 4\,s. \\
\\
%We processed the same data using a short-time Fourier transform (STFT), checking if the frequency extraction could be done in a shorter delay. 
%In the first 5 seconds we therefore applied STFT on 0.5$s$ frames for the first second, on 1$s$ frames for the second second, on 2$s$ frames for the third and fourth second, and on 4$s$ frames for the fifth and sixth second. The results are illustrated in figure \ref{fig:all-results-reconn}. STFT has similar performances then CCA in the first seconds of processing, but does not improve the performances as much as the CCA for longer delays.\\
\\
Finally, we did some preliminary experiments combining the use of EEG signals as illustrated above with some processing of the gyroscope mounted on the EEG headset. 
In our tests we used the lateral movement of the head to trigger the recognition. 
This allows the operator non only to start a recognition by moving the head toward a new target but also to restart the process after a wrong recognition by shaking shortly the head laterally. 
A video illustrating the approach can be accessed at \verb"www.bit.ly/ssvep-bot". 
These preliminary tests improved significantly the whole interaction and show the merit of combining the EEG-based implicit communication with other human-robot interaction methods.

%The small variation also suggests that the prediction system used, as it is, will not provide better results. 
\begin{figure}
\center
\includegraphics[width=0.7\textwidth]{figures/all_time_reconn.pdf}
\caption{Frequency recognition rate versus time during the 15\,s of stimulation for two processing methods: canonical correlation analysis (CCA) and short-time Fourier transform (STFT). These numbers are an average over 10 subjects considering the 5 trials of 15\,s each and the stimulation frequencies (8, 10, and 12\,Hz).} \label{fig:all_time_reconn}
\end{figure}

\begin{figure}
\center
\includegraphics[width=0.7\textwidth]{figures/taux-reconn.pdf}
\caption{Frequency recognition rate per stimulation frequency and per delay between start of stimulation and start of recognition process. These numbers are an average over 10 subjects considering the 5 trials of 15\,s each and the stimulation frequencies (8, 10, and 12\,Hz). The figures for each subject are detailed in Figure \ref{fig:all-results-reconn}.}
\label{fig:taux-reconn}
\end{figure}

\begin{table}\begin{center}
    \begin{tabular}{ c | r | r | r | r | r | r |}
        & \multicolumn{6}{c|}{Recognition rate} \\ 
        & \multicolumn{2}{c|}{delay 0\,s} & \multicolumn{2}{c|}{delay 2\,s} & \multicolumn{2}{c|}{delay 4\,s} \\ 
        Stimuli freq.& average & std deviation & average & std deviation & average & std deviation \\ \hline

         8\,Hz & 69.8\% & 18.8\% & 72.8\% & 20.0\% & 75.1\% & 19.8\% \\
        10\,Hz & 73.2\% &  5.0\% & 78.9\% & 5.9\% & 81.9\% & 8.2\% \\
        12\,Hz & 59.2\% & 13.6\% & 63.9\% & 14.2\% & 66.0\% & 15.1\% \\ \hline
    \end{tabular}
    \caption{Frequency recognition rate per stimulation frequency and per delay between start of stimulation and start of recognition process. These data are plotted in Figure~\ref{fig:taux-reconn}.}
\end{center}\end{table}

\begin{figure}
\center
\includegraphics[width=0.98\textwidth]{figures/all-results-reconn.pdf}
\caption{Frequency recognition rate per subject and per stimulation frequency, considering the different stimulation durations.}
\label{fig:all-results-reconn}
\end{figure}


\begin{table}[ht]
\begin{center}
    \begin{tabular}{ r | c | c | c | c || r | c | c | c | c }
        \multicolumn{2}{c|}{} & 0\,s & 2\,s & 4\,s & \multicolumn{2}{c|}{} & 0\,s & 2\,s & 4\,s \\ \hline

        \multirow{3}{*}{subject1} &  8\,Hz & 93.3\% & 96.2\% & 98.2\% & \multirow{3}{*}{subject2} &  8\,Hz & 73.3\% & 79.2\% & 83.6\% \\
                                  & 10\,Hz & 73.3\% & 77.2\% & 77.5\% & & 10\,Hz & 70.0\% & 73.5\% & 77.7\% \\
                                  & 12\,Hz & 76.3\% & 83.1\% & 83.9\% & & 12\,Hz & 58.7\% & 64.6\% & 69.5\% \\
         
        \hline

        \multirow{3}{*}{subject3} &  8\,Hz & 79.7\% & 84.2\% & 86.8\% & \multirow{3}{*}{subject4} &  8\,Hz & 88.6\% & 93.1\% & 94.5\% \\
                                  & 10\,Hz & 77.5\% & 88.5\% & 96.2\% & & 10\,Hz & 80.0\% & 84.9\% & 88.6\% \\
                                  & 12\,Hz & 78.3\% & 80.0\% & 78.6\% & & 12\,Hz & 60.3\% & 64.2\% & 72.3\% \\
        
        \hline

        \multirow{3}{*}{subject5} &  8\,Hz & 53.9\% & 52.5\% & 54.8\% &  \multirow{3}{*}{subject6} &  8\,Hz & 72.4\% & 75.8\% & 75.0\% \\
                                  & 10\,Hz & 74.6\% & 79.8\% & 80.8\% & & 10\,Hz & 63.7\% & 68.4\% & 67.7\% \\
                                  & 12\,Hz & 36.6\% & 38.5\% & 34.0\% & & 12\,Hz & 48.9\% & 52.3\% & 58.2\% \\

        \hline

        \multirow{3}{*}{subject7} &  8\,Hz & 36.3\% & 40.0\% & 41.8\% & \multirow{3}{*}{subject8} &  8\,Hz & 89.0\% & 93.8\% & 95.9\% \\
                                  & 10\,Hz & 75.7\% & 80.8\% & 83.2\% & & 10\,Hz & 75.6\% & 82.4\% & 84.8\% \\
                                  & 12\,Hz & 45.2\% & 50.8\% & 50.9\% & & 12\,Hz & 53.3\% & 59.2\% & 62.3\% \\

        \hline

        \multirow{3}{*}{subject9} &  8\,Hz & 57.8\% & 59.0\% & 62.9\% & \multirow{3}{*}{subject10} &  8\,Hz & 53.7\% & 54.6\% & 57.3\% \\
                                  & 10\,Hz & 66.7\% & 73.4\% & 74.0\% & & 10\,Hz & 74.6\% & 80.0\% & 88.8\% \\
                                  & 12\,Hz & 71.3\% & 77.1\% & 73.7\% & & 12\,Hz & 63.0\% & 69.2\% & 76.8\% \\

        \hline
                                  

    \end{tabular}
    \caption{Frequency recognition rate per subject and per stimulation frequency, considering the different stimulation durations corresponding to the plot of Fig.~\ref{fig:all-results-reconn}}.
\end{center}\end{table}

\section{Conclusions}
This study systematically analyzes two established SSVEP-related EEG classification techniques and some of their key parameters for tackling the robot selection problem using the Emotiv EPOC and the Thymio robot, and proposes a new methodology for addressing proximal HSI using implicit communication. 
With respect to the existing literature based on explicit gesture or voice-based interaction, this approach uses implicit information that is not culture-dependent and does not require prior learning. 
With respect to other potential gaze-based approaches, such as eye-tracking devices, the CCA-based SSVEP classifier does not require training nor calibration while still obtaining performances that can reach success rates well above 75\% for some individuals.\\
\\
This is also the first study giving an estimation of the potential distance of robot detection using this technique.
Despite the limited range observed in our experiments, less than 2\,m, this distance has to be considered with respect to the size of the robot and the type of visual stimuli. We consider that the setup used in this experiment is equivalent to a robot with a diameter of 60\,cm placed up to 10\,m away and having a blinking LED of 7.5\,W. 
We can speculate that these conditions are realistic for a concrete application.\\
\\
One limitation of the current setup comes from the number of available frequencies.
Although theoretically the 8\,Hz to 12\,Hz frequency range could allow the classification of up to 20 different frequencies~\cite{SSVEPfiability}, the number of possible detected robots limits the scalability of the approach. 
However, this selection technique could be combined with other approaches, such as detection of head orientation, allowing operators to pre-select part of the swarm and to use the EEG-based technique for a subset of the swarm.\\
\\
Another limitation of this approach is the required delay of four seconds before recognition.
This delay is similar to the delay of gesture recognition or speech interaction when considering the complete time of interaction.
This could possibly be solved using more sophisticated processing chains -- for instance, combining CCA with STFT.
More importantly, such limitations of EEG processing techniques could be solved using one of greatest advantages of this approach: its possibility of combination with other HRI channels.
Indeed, the implicit communication used in SSVEP means that integrating EEG analysis in other scenarios could enhance the global performance of the setup without requiring any additional effort from the operator.\\
\\
Some factors that are uncontrollable in real world applications, such as muscular artifacts or personal attitudes of the pilot, could negatively impact the performances of such a solution.
This can be particularly significant if the robots are moving and the operator needs to track them visually. 
Other factors, such as the relative surrounding brightness, the variable distance to the targets, and blinking light interferences with other robots, should be carefully considered to reach optimal performance. \\
\\
In conclusion we believe that despite the limiting factors highlighted by our work, the very positive results show that an efficient combination of EEG and swarm, collective, or distributed robotics could open new interesting possibilities in HSI.\\



% Finally, while some factors that are uncontrollable in a real world application, such as muscular artifacts; the relative surrounding brightness, variable distance to the targets and blinking light interferences from other robots must still be controlled; 

\begin{acknowledgement}
Many thanks to Dr. Ricardo Chavarriaga, Dr. Claire Braboszcz and Dr. Serafeim Perdikis for the constructive discussions about experiments involving EEG, to Dr. J\'er\^ome Scherer and Prof. Marco Picasso for their help on mathematical issues in the signal processing, and to all subjects who were available for the experiments. This work was partially supported by the Swiss National Center of Competence in Research ``Robotics."
\end{acknowledgement}

\bibliography{mybib}

\end{document}
